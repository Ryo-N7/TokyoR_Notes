---
title: "Untitled"
always_allow_html: yes
output: 
  md_document:
    variant: markdown_github
---

Within a typhoon, another TokyoR Meetup! ... well not really it turned out to be a false alarm and the weather was a wonderful 30 degrees Celsius with 800% humidity as usual. My gripes with the weather aside this month's meetup was held at [Cresco](), a , in their headquarters in Shinagawa, Tokyo.

<img src="https://i.imgur.com/UlstyyS.png" style="display: block; margin: auto;" width = "350" />

In line with my previous round up posts:

- [TokyoR #76](https://ryo-n7.github.io/2019-03-07-tokyoR-76-roundup/)
- [TokyoR #77](https://ryo-n7.github.io/2019-04-24-tokyoR-77/)) 
- [TokyoR #78](https://ryo-n7.github.io/2019-05-31-tokyoR-78-roundup/) 
- [TokyoR #79](https://ryo-n7.github.io/2019-07-05-tokyoR-79-roundup/)

I will be going over around half of all the talks. Hopefully, my efforts will help spread the vast knowledge of Japanese R users to the wider R community. Throughout I will also post helpful blog posts and links from other sources if you are interested in learning more about the topic of a certain talk. You can follow __Tokyo.R__ by searching for the [#TokyoR](https://twitter.com/hashtag/TokyoR) hashtag on Twitter.

Anyways...

Let's get started!

# BeginneR Session

As with every [TokyoR](http://tokyor.connpass.com/) meetup, we began with a set of beginner user focused talks:

- [Reading in data with R by kotatyamtema](https://www.slideshare.net/kotora_0507/tokyor79-beginnerssession1/kotora_0507/tokyor79-beginnerssession1)
- [Data handling & manipulation by y_mattu](https://ymattu.github.io/TokyoR80/slide.html)

# Main Talks

## [ill_identified](https://twitter.com/ill_Identified): Econometrics vs. Machine Learning
* [Slides](https://speakerdeck.com/ktgrstsh/relation-between-econometrics-and-machine-learning-ai-is-the-plan-the-plan-is-counterfactual)



3 Main Topics:
* A.I. and Causal Inference
* Evolution of Machine Learning
* A.I. == Econometrics

- Relation between econometrics & machine learning! 
- Economics == Inference vs. Machine Learning == Prediction
- https://qiita.com/KanNishida/items/39bee9723c589e669b1e
- Randomized Control Trials (RCTs)
-
- Difference-In-Differences (DID)

There was a talk on DID at last year's [Japan.R Conference]() that you can find [here]()!

- Judea Pearl (2019): 7 tools of causal inference wit hreflections on machine learning
- [text](https://cacm.acm.org/magazines/2019/3/234929-the-seven-tools-of-causal-inference-with-reflections-on-machine-learning/fulltext)
-- 3-level causal hierarchy: Association >>> Intervention >>> Counterfactuals

[Frank Harrell]()'s blog post on [](https://www.fharrell.com/post/stat-ml/)

- Susan Athey, Guido Imbens, Viktor Chernozhukov
- Double/de-biased machine learning (DML) - 2017
- Susan Athey's [causal tree](https://t.co/OW8VFGtjRr) R package
- Discrimination and fairness in AI 
- Statistical discrimination in econometrics
- causal discovery
- AlphaGo == AI
- DeepBlue
-

## [kilometer00](https://twitter.com/kilometer00): R interface to Python
* [Slides](https://speakerdeck.com/kilometer/tokyo-dot-r-number-80-r-interface-to-python)

TokyoR organizer and frequent BeginneR session speaker `@kilometer00` talked about using Python with R. 

To familiarize the audience with Python he went over quite a number of slides showing the similarities and differences in syntax between the two languages.

<p float="left" align="center">
<img src="../assets/2019-07-05-tokyoR-79-roundup_files/whatisdata.JPG" width="49%" />
<img src="../assets/2019-07-05-tokyoR-79-roundup_files/whatisdata2.JPG" width="49%" />
</p>

Next, `@kilometer00` talked about the {reticulate} package which allows you to call Python from R and can provide translation between R and Python objects (such as R and Pandas data frames or R matrices and NumPy arrays). Using {reticulate} he talked about the importance of having an isolated and independent environment, to keep Python in a "sandbox"-ed virtual environment for security and reproducibility. To do this `@kilometer00` likes to use [Pipenv](https://github.com/pypa/pipenv/).

![]()

Once you're done with all the set-up, you can install {reticulate} from CRAN and attach your Python virtualenv with `reticulate::use_python()` and then you can finally start doing stuff! But be wary of type errors when you're coding:

![]()

You can also use Python in a R Markdown document by setting the code chunk to run it. With a recent development in RMD you can now also share objects from different languages by putting a prefix on front of the object name!

![]()

Funnily enough you can also run R in Python in R:

![]()

Pythonception!

More resources on {reticulate}:
* [{reticulate} package website](https://rstudio.github.io/reticulate/index.html)
* [R or Python? Why not both? Using Anaconda Python within R with {reticulate} - Bruno Rodrigues](https://www.brodrigues.co/blog/2018-12-30-reticulate/)
* [R and Python: Using reticulate to get the best of both worlds - Manuel Tilgner](https://www.statworx.com/de/blog/r-and-python-using-reticulate-to-get-the-best-of-both-worlds/)

# LTs

## [wkwk_soprano](https://twitter.com/wkwk_soprano): Creating network graphs with R!
* [Slides](https://speakerdeck.com/wmichi/rdegurahuzuo-rufalse)

It's been a while since `@wkwk_soprano` used R (5 years!) but he's come back with aplomb by talking about network graphs at Tokyo.R! Network graphs are used in all sorts of fields of study including physics, chemistry, linguistics, and the social sciences. In industry you might see them as part of a recommendation graph between a customer and products on sale. Frustrated by the fact that he didn't have a fun dataset to use the {network} package on, `@wkwk_soprano` decided to create his own data set based on his favorite manga, One Piece!

By counting up the times a character appeared in one panel of the manga with another he slowly built up a co-occurence matrix of all the characters from Volume 1 to Volume 23. It took him about one hour per volume to create this data set, now that's dedication!

![]()

You can find the gum-gum fruits of his labour [here](https://drive.google.com/file/d/1y0uDbPLsMBoC5KpjT9CDDmQLAuOmZK2N/view).

After creating the data `@wkwk_soprano` wanted to do some analysis on it like graph embedding via DeepWalk or Large-scale Information Network Embedding (LINE). There's actually a R package called [Rline](https://github.com/YosefLab/Rline) to implement this method but he found that it was difficult to install and it hadn't been updated in a while so he went with the original [C++ implementation](https://github.com/tangjianpku/LINE) from Jian Tang et al. The result was an output of the distributed representation of all the characters in the data.

![]()

Lastly, `@wkwk_soprano` wanted to find similarities between One Piece characters so he used cosine similarity using [this code snippet](https://gist.github.com/wmichi/6b60b12543bfeb3205cff32d6adc3995) which allows you to extract top 'N' similar items from network embedding matrices. Taking a look at some popular characters he was somewhat disappointed in the results as from his extensive knowledge of the story he knew some of the character similarities just weren't right!

![]()

More resources on network analysis in R:

* [Intro to Network Analysis with R - Jesse Sadler](https://www.jessesadler.com/post/network-analysis-with-r/)
* [Network Centrality in R: An Introduction with {netrankr} - David Schoch](http://blog.schochastics.net/post/network-centrality-in-r-introduction/)


## [gepuro](https://twitter.com/gepuro): Translating `tidyverse.org` into Japanese!
* [Slides](https://www.slideshare.net/gepuro/tidyverseorg)

Organizer of the annual [Japan.R Conference](http://japanr.net/)

After being involved in the Japanese translation of [Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists](), `@gepuro` thought about trying his hand at translating `tidyverse.org` in Japanese!

In recent months there have been big changes in major `tidyverse` packages such as {dplyr} and {ggplot2} with accompanying articles to boot. These articles, especially the new pivot functions vignette, are the ones `@gepuro` and fellow TokyoR community members such as `@Atsusy` have started working on in the past few weeks. To do the translation there are three key steps:

1. Create a Github account
2. Log into GitLocalize
3. Access the specific GitLocalize repo where your translation project is located

GitLocalize looks like this:

![]()

Once you're done, you create a "Review Request" which is checked by the maintainer `@gepuro` for any errors. He'll receive the "Review Request" as a Pull Request on the `R Lang Document JA` repo and if everything is OK it'll be merged in!

There are other ways to contribute to the project as well such as: 

* Helping to make the text sound more naturally Japanese
* Create the blogdown website of the Japanese translation
* Create a vocab list of common R terminology in Japanese to use as a reference
* and more!

I enjoyed this talk as it was similar to the talk by Riva Quiroga on translating the "R for Data Science" book and R data sets into Spanish that I heard at user!2019 a few weeks ago (the talk is covered in my [blogpost here](https://ryo-n7.github.io/2019-07-21-user2019-reflections/)). [here](https://ryo-n7.github.io/2019-07-21-user2019-reflections/). If you're good at English and Japanese you can join the #translation channel on the Tokyo.R slack!

In other news, there was an announcement that this year's [Japan.R Conference](http://japanr.net/) will be on December 7th!

## Other Talks

* [airspace_nobo: Use Python from R!](https://speakerdeck.com/airspace_nobo/use-r-from-python)
* [kodachan: Proxy authentication with R!]()
* [k871: R in a Traditional Japanese Manufacturing Company!]()

# Food, Drinks, and Conclusion

`TokyoR` happens almost monthly and it’s a great way to mingle with Japanese R users as it's the largest regular meetup here in Japan. We're finally taking a break next month so the next meetup will be on September 28 and it will be a special session in __Shiny__!

Talks in English are also welcome so if you’re ever in Tokyo come join us!