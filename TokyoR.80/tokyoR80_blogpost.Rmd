---
title: "Untitled"
always_allow_html: yes
output: 
  md_document:
    variant: markdown_github
---

Within a typhoon, another TokyoR Meetup! ... well not really it turned out to be a false alarm and the weather was a wonderful 30 degrees Celsius with 800% humidity as usual. My gripes with the weather aside this month's meetup was held at [Cresco](), a , in their headquarters in Shinagawa, Tokyo.

<img src="https://i.imgur.com/UlstyyS.png" style="display: block; margin: auto;" width = "350" />

In line with my previous round up posts:

- [TokyoR #76](https://ryo-n7.github.io/2019-03-07-tokyoR-76-roundup/)
- [TokyoR #77](https://ryo-n7.github.io/2019-04-24-tokyoR-77/)) 
- [TokyoR #78](https://ryo-n7.github.io/2019-05-31-tokyoR-78-roundup/) 
- [TokyoR #79](https://ryo-n7.github.io/2019-07-05-tokyoR-79-roundup/)

I will be going over around half of all the talks. Hopefully, my efforts will help spread the vast knowledge of Japanese R users to the wider R community. Throughout I will also post helpful blog posts and links from other sources if you are interested in learning more about the topic of a certain talk. You can follow __Tokyo.R__ by searching for the [#TokyoR](https://twitter.com/hashtag/TokyoR) hashtag on Twitter.

Anyways...

Let's get started!

# BeginneR Session

As with every [TokyoR](http://tokyor.connpass.com/) meetup, we began with a set of beginner user focused talks:

- [Reading in data with R by kotatyamtema](https://www.slideshare.net/kotora_0507/tokyor79-beginnerssession1/kotora_0507/tokyor79-beginnerssession1)
- [Data handling & manipulation by y_mattu](https://ymattu.github.io/TokyoR80/slide.html)

# Main Talks

## `ill_identified`: Econometrics vs. Machine Learning
* [Slides](https://speakerdeck.com/ktgrstsh/relation-between-econometrics-and-machine-learning-ai-is-the-plan-the-plan-is-counterfactual)

- Relation between econometrics & machine learning! 
- Economics == Inference vs. Machine Learning == Prediction
- https://qiita.com/KanNishida/items/39bee9723c589e669b1e
- Randomized Control Trials (RCTs)
-
-
-
-
- Difference-In-Differences (DID)
-
-
-
-

There was a talk on DID at last year's [Japan.R Conference]() that you can find [here]()!

- Judea Pearl (2019): 7 tools of causal inference wit hreflections on machine learning
- [text](https://cacm.acm.org/magazines/2019/3/234929-the-seven-tools-of-causal-inference-with-reflections-on-machine-learning/fulltext)
-- 3-level causal hierarchy: Association >>> Intervention >>> Counterfactuals


[Frank Harrell]()'s blog post on [](https://www.fharrell.com/post/stat-ml/)


- Susan Athey, Guido Imbens, Viktor Chernozhukov
- Double/de-biased machine learning (DML) - 2017
- Susan Athey's [causal tree](https://t.co/OW8VFGtjRr) R package
- Discrimination and fairness in AI 
- Statistical discrimination in econometrics
- causal discovery
- AlphaGo == AI
- DeepBlue
-

## [kilometer00](): R interface to Python
* [Slides]()

TokyoR organizer and frequent BeginneR session speaker `@kilometer00` talked about using Python with R. 

To familiarize the audience with Python he went over quite a number of slides showing the similarities and differences in syntax between the two languages.

<p float="left" align="center">
<img src="../assets/2019-07-05-tokyoR-79-roundup_files/whatisdata.JPG" width="49%" />
<img src="../assets/2019-07-05-tokyoR-79-roundup_files/whatisdata2.JPG" width="49%" />
</p>

{reticulate} package

- differences in programming with R vs. Python (var assignment, var naming, var type, etc.)
- {reticulate}
- isolated + independent environment >>> sandboxed Python in virtual environment 
-- security + reproducibility
- `Pipenv` >>> sandboxed python manager 
-- create virtualenv
- install.package(reticulate)
-- attach the python virtualenv! >>> `use_python()`
-- `py_config()` check your version, other sessionInfo
- `source_python()` >>> import python source file
- benchmark test for reading in csv files
- use Python in RMD: ```{python}   import pandas as pd blahblah ```
-- share py-object between chunks!
- import R object to a Python chunk using prefix `r.ObjectName`
- import python object to R chunk
- Using python interactively within an R session
- `reticulate::repl_python()` 
`>>> a = 1 `
`>>> import pandas as pd`
`>>>> df = r.iris`
`>>> ESC`  escape back to R!
`>>> import pyper` Run R in Python in R!!
`>>> r = pyper.R()`
`>>> r("set.seed(71)")`

# LTs

## @wkwk_soprano 	Rでグラフつくるの！ 	[資料]
* [Slides](https://speakerdeck.com/wmichi/rdegurahuzuo-rufalse)

It's been a while since `@wkwk_soprano` used R (5 years!) but he's come back with aplomb by talking about network graphs at Tokyo.R! Network graphs are used in all sorts of fields of study including physics, chemistry, linguistics, and the social sciences. In industry you might see them as part of a recommendation graph between a customer and products on sale. Frustrated by the fact that he didn't have a fun dataset to use the {network} package on, `@wkwk_soprano` decided to create his own data set based on his favorite manga, One Piece!

By counting up the times a character appeared in one panel of the manga with another he slowly built up a co-occurence matrix of all the characters from Volume 1 to Volume 23. It took him about one hour per volume to create this data set, now that's dedication!

![]()

You can find the gum-gum fruits of his labour [here](https://drive.google.com/file/d/1y0uDbPLsMBoC5KpjT9CDDmQLAuOmZK2N/view).

After creating the data `@wkwk_soprano` wanted to do some analysis on it like graph embedding via DeepWalk or Large-scale Information Network Embedding (LINE). There's actually a R package called [Rline](https://github.com/YosefLab/Rline) to implement this method but he found that it was difficult to install and it hadn't been updated in a while so he went with the original [C++ implementation](https://github.com/tangjianpku/LINE) from Jian Tang et al. The result was an output of the distributed representation of all the characters in the data.

![]()

Lastly, `@wkwk_soprano` wanted to find similarities between One Piece characters so he used cosine similarity using [this code snippet](https://gist.github.com/wmichi/6b60b12543bfeb3205cff32d6adc3995) which allows you to extract top 'N' similar items from network embedding matrices. Taking a look at some popular characters he was somewhat disappointed in the results as from his extensive knowledge of the story he knew some of the character similarities just weren't right!

![]()

More resources on network analysis in R:

* [Intro to Network Analysis with R - Jesse Sadler](https://www.jessesadler.com/post/network-analysis-with-r/)


## @gepuro tidyverse.orgの翻訳
* [Slides](https://t.co/xPwQZDMhAN?amp=1)

Organizer of the annual [Japan.R Conference](http://japanr.net/)

After being involved in the Japanese translation of [Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists](), `@gepuro` thought about trying his hand at translating `tidyverse.org` in Japanese!

In recent months there have been big changes in major `tidyverse` packages such as {dplyr} and {ggplot2} with accompanying articles to boot. These articles especially the new pivot functions vignette are the ones `@gepuro` and fellow TokyoR community members such as `@Atsusy` have slowly began work on in the past few weeks.

- new `dplyr`, new `ggplot2` etc.
- Github >>> gitlocalize translation tool
- LEFT original vs. RIGHT translation
- Create Review Request >>> PR 
- 

Similar to the talk from [useR! 2019]() by Riva Quiroga on translating the "R for Data Science" book and R data sets into Spanish, which is covered in my blogpost  [here](https://ryo-n7.github.io/2019-07-21-user2019-reflections/).

In other news there was an announcement that this year's Japan.R Conference will be on December 7th!

# Food, Drinks, and Conclusion

`TokyoR` happens almost monthly and it’s a great way to mingle with Japanese R users as it's the largest regular meetup here in Japan. We're finally taking a break next month so the next meetup will be on September 28 and it will be a special session in __Shiny__!

Talks in English are also welcome so if you’re ever in Tokyo come join us!